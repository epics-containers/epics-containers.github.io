<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Kubernetes Cluster Config &mdash; epics_containers 0.6+3.gec61b9a documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/theme_overrides.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/k8s-epics2.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Add an IOC instance to a beamline" href="../how-to/add_ioc.html" />
    <link rel="prev" title="Channel Access and Other Protocols" href="net_protocols.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: rgb(7, 43, 93)" >
            <a href="../index.html" class="icon icon-home"> epics_containers
            <img src="../_static/k8s-epics2.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                main
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
  
              <p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/setup_k8s.html">Setup a Kubernetes Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/useful_k8s.html">Useful Kubernetes Additions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/create_beamline.html">Create a beamline repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/deploy_example.html">Deploy The Example IOC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/manage_iocs.html">Manage IOCs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Explanations</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Essential Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_in.html">epics-containers Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="net_protocols.html">Channel Access and Other Protocols</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Kubernetes Cluster Config</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#cluster-options">Cluster Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dls-argus-cluster">DLS Argus Cluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#beamline-local-cluster-nodes">Beamline Local Cluster Nodes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#metallb-pools">Metallb Pools</a></li>
<li class="toctree-l4"><a class="reference internal" href="#node-labelling-and-taints">Node Labelling and Taints</a></li>
<li class="toctree-l4"><a class="reference internal" href="#host-network">Host Network</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#uses-for-argus">Uses for Argus</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How-to Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../how-to/add_ioc.html">Add an IOC instance to a beamline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how-to/create_ioc.html">Create a new generic IOC image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how-to/run_iocs.html">Run an IOC without Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how-to/debug.html">Debug an IOC instance locally</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how-to/debug.html#debug-an-ioc-instance-in-kubernetes">Debug an IOC instance in Kubernetes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/cli.html">Command Line Interface for IOC Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/contributing.html">Contributing</a></li>
</ul>

  <!-- Add versions for selected branches + tags -->
  <p class="caption">
    <span class="caption-text">Versions</span>
  </p>
  <ul id="versions"/>
  <script>
    // Add any branches to appear in the side pane here, tags will be added below
    // Will only appear if docs are built and pushed in gh-pages
    var versions = ['main', 'master'];
    var dirs = new Set();
    function addVersion(name) {
      if (dirs.has(name)) {
        var li = document.createElement("li");
        var a = document.createElement("a");
        a.href = 'https://epics-containers.github.io/epics_containers/' + name;
        a.innerText = name;
        li.appendChild(a)
        document.getElementById('versions').appendChild(li);
      }
    }
    Promise.all([
      // Find gh-pages directories and populate `dirs`
      fetch("https://api.github.com/repos/epics-containers/epics_containers/contents?ref=gh-pages")
      .then(response => response.json())
      .then(data => data.forEach(function(e) {
        if (e.type == "dir") dirs.add(e.name);
      })),
      // Add tags to `versions`
      fetch('https://api.github.com/repos/epics-containers/epics_containers/tags')
        .then(response => response.json())
        .then(data => data.forEach(function(e) {
          versions.push(e.name);
        }))
      ]).then(_ => versions.forEach(addVersion))
  </script>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: rgb(7, 43, 93)" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">epics_containers</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Kubernetes Cluster Config</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/explanations/kubernetes_cluster.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="kubernetes-cluster-config">
<h1>Kubernetes Cluster Config<a class="headerlink" href="#kubernetes-cluster-config" title="Permalink to this headline"></a></h1>
<section id="cluster-options">
<h2>Cluster Options<a class="headerlink" href="#cluster-options" title="Permalink to this headline"></a></h2>
<p>Three cluster topologies were considered for this project.</p>
<dl class="field-list simple">
<dt class="field-odd">Cluster per beamline</dt>
<dd class="field-odd"><p>This could be as simple as
a single server: the K3S installation described in
<a class="reference internal" href="../tutorials/setup_k8s.html#setup-kubernetes"><span class="std std-ref">Setup a Kubernetes Server</span></a> may be sufficient. The documentation at
<a class="reference external" href="https://rancher.com/docs/k3s/">https://rancher.com/docs/k3s/</a> also details how to make a high availability
cluster, requiring a minimum of 4 servers.
This approach keeps the configuration of the clusters quite straightforward
but at the cost of having multiple separate clusters to maintain. Also
it requires control plane servers for every beamline, whereas a centralized
approach would only need a handful of control plane servers for the entire
facility.</p>
</dd>
<dt class="field-even">Central Facility Cluster</dt>
<dd class="field-even"><p>A central facility cluster that runs
all IOCs on its own nodes would keep everything centralized and provide
economy of scale. However, there are significant issues with routing
Channel Access, PVA and some device protocols to IOCs running in a
different subnet to the beamline. DLS spent some time working around these
issues but eventually abandoned this approach.</p>
</dd>
<dt class="field-odd">Beamline Worker Nodes</dt>
<dd class="field-odd"><p>This approach uses the central
cluster but adds remote beamline nodes located in the beamline itself,
connected to the beamline subnet. This has all the benefits of central
management but is able to overcome the problems with protocol routing.
The DLS argus cluster configuration described below is an example of
how to achieve this.</p>
</dd>
</dl>
</section>
<section id="dls-argus-cluster">
<span id="argus"></span><h2>DLS Argus Cluster<a class="headerlink" href="#dls-argus-cluster" title="Permalink to this headline"></a></h2>
<p>This section gives details of the topology and special
configuration used by the DLS argus cluster to enable running
IOCs on a Beamline.</p>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h3>
<p>Argus is the production DLS cluster. It comprises 22 bare metal worker nodes, with a 3 node control plane that runs in VMs. The control plane nodes run the K8s master processes such as the API server, controller manager etc. Each control plane node runs an etcd backend.</p>
<img alt="../_images/clusterHA.png" src="../_images/clusterHA.png" />
<p>To load balance across the K8s API running on the control plane nodes, there is a haproxy load balancer. The DNS endpoint argus.api.diamond.ac.uk (which all nodes use as the main API endpoint) points to a single haproxy IP. The IP is HA by virtue of a pair of VMs that both run haproxy, bind on all IPs, and use VRRP/keepalived to make sure the IP is always up. Haproxy has the 3 control plane nodes as a target backend.</p>
<img alt="../_images/kubeadm-ha-topology-stacked-etcd.png" src="../_images/kubeadm-ha-topology-stacked-etcd.png" />
<p>The cluster uses Kubeadm to deploy the K8s control plane in containers. It is provided by K8s upstream, and is architecturally similar to Rancher Kubernetes Engine (RKE). Kubeadm supports upgrades/downgrades and easy provisioning of nodes. The cluster is connected using Weave as the CNI. Weave is the only CNI tested that passes Broadcast/Unicast/Multicast (BUM) traffic through the iptables that control network access for pods. Metallb is used as a component to support K8s loadBalancer Service objects. Ingress nginx from nginxinc is used as an ingress controller. Logs are collected from the stdout of all pods using a fluentd daemonset which ships logs to a centralized graylog server. Cluster authentication is via KeyCloak.</p>
<p>The cluster sits in one rack, with a top of rack (TOR) switch/router connecting it to the rest of the network. The cluster nodes sit on the same /22 network which is routable via the TOR router (this router routes the /22 subnet to other racks via OSPF). Metallb pool IPs are allocated from within this /22 to ensure they are globally routable by the OSPF network; the metallb speaker pods respond to ARP requests originating from the TOR router looking for load balanced Service IPs.</p>
<p><strong>One of the Argus racks</strong></p>
<img alt="../_images/argus3.jpg" src="../_images/argus3.jpg" />
<p>The cluster is built and managed using Ansible. Heavy use of the k8s module enables direct installation of K8s components by talking directly to the K8s API using the k8s module. Ansible also configures the haproxy API load balancer. Prometheus_operator provides the monitoring stack.</p>
<p>Argus is a multi-tenant cluster. Namespaces are used to enforce multi-tenancy. A namespace is created on demand for each user, acting as a sandbox for them to get familiar with K8s. Applications deployed in production get their own “project” namespace. The project namespace has some associated policy that determines who can run pods in the namespace, what data can be accessed, and if pods can run with elevated privileges. This is enforced by a combination of RBAC and Pod Security Policy (PSP). The latter is a deprecated feature in K8s 1.21 and will soon be replaced with Open Policy Agent.</p>
</section>
<section id="beamline-local-cluster-nodes">
<h3>Beamline Local Cluster Nodes<a class="headerlink" href="#beamline-local-cluster-nodes" title="Permalink to this headline"></a></h3>
<p>As part of the investigation work some worker nodes in Argus have been connected that are physically located at the beamline. These nodes do not share the same rack as Argus, and hence are part of a different routed subnet to the /22 that the control plane and main workers are within. This model assumes one centralised control plane (and some generic workers), and a set of beamline cluster nodes that may be distributed across the network (in different subnets).</p>
<p>The beamline cluster nodes require a few interesting sets of configuration to make this architecture work. See the following subheadings for details.</p>
<section id="metallb-pools">
<h4>Metallb Pools<a class="headerlink" href="#metallb-pools" title="Permalink to this headline"></a></h4>
<p>Metallb cannot be used to provide loadBalancer services for pods running on the beamline cluster nodes. This is because metallb currently only supports a single pool of IPs to allocate from. In the case of Argus, the pool is allocated from within the /22 in which the control plane (and a few generic workers) sit. Should a pod with a loadBalancer Service IP get brought up on a beamline cluster node, the traffic would not be routable because the beamline TOR switch does not send ARP messages for subnets that it is not directly connected to. This is not an issue running IOCs since they do not make use of loadBalancer Services. There is a feature request for Metallb to support address pools that is currently pending.</p>
</section>
<section id="node-labelling-and-taints">
<h4>Node Labelling and Taints<a class="headerlink" href="#node-labelling-and-taints" title="Permalink to this headline"></a></h4>
<p>The beamline cluster worker nodes are labelled and tainted with the name of the beamline. This ensures that only pods running IOCs that are relevant to that beamline can be started on the beamline worker nodes. Pods that are to be scheduled there must tolerate the taint, and use node selection based on the label.</p>
<p>Certain utility pods must also tolerate the beamline name taint. Pods such as fluentd (which provides pod log aggregation and shipping to a centralised graylog) need additional tolerations of the taint. However most standard utilities such as Prometheus, Weave (the CNI itself runs in a pod) and kube-proxy all have a toleration of all “noSchedule” taints built in.</p>
</section>
<section id="host-network">
<h4>Host Network<a class="headerlink" href="#host-network" title="Permalink to this headline"></a></h4>
<p>In order for IOCs to work within K8s pods, they typically need to see BUM traffic. This is because EPICS uses UDP Broadcast for IOC discovery. There are also other interesting network quirks that IOCs exhibit that make use of the CNI network overlay unsuitable. To get around this, pods running IOCs make use of the host network namespace. In other words, they see the interfaces on the underlying worker nodes, rather than a virtual interface that is connected to the cluster internal network that normal pods see. This is done by setting hostNetwork =  true in the pod spec. Access to the host network namespace requires privileged pods. Whilst this is allowed (Argus uses pod security policy to enforce the attributes of the pods that are scheduled), we do drop the capabilities that are not needed. This reduces the attack surface somewhat. We drop everything except NET_ADMIN and NET_BROADCAST.</p>
</section>
</section>
</section>
<section id="uses-for-argus">
<h2>Uses for Argus<a class="headerlink" href="#uses-for-argus" title="Permalink to this headline"></a></h2>
<p>The central cluster is used for many services other than EPICS IOCs. Below is
a list of current and potential use cases:</p>
<ul class="simple">
<li><p>Controls IOCs</p></li>
<li><p>Kafka and Spark</p></li>
<li><p>Jenkins</p></li>
<li><p>Sonarqube</p></li>
<li><p>Zocalo</p></li>
<li><p>Jupyterhub</p></li>
<li><p>Business apps (Confluence, Jira etc)</p></li>
<li><p>Monitoring stacks (ElasticSearch, Graylog, Graphite, Nagdash etc)</p></li>
<li><p>Core services (LDAP, Kerberos, Gitlab etc)</p></li>
<li><p>Netbox</p></li>
<li><p>MariaDB</p></li>
<li><p>HT Condor</p></li>
<li><p>Machine Learning toolkits (Kubeflow)</p></li>
<li><p>VM orchestration (Kubevirt/Virtlet)</p></li>
<li><p>Relion</p></li>
<li><p>Storage Systems deployment (Ceph-rook, Portworkx etc)</p></li>
<li><p>XChem Fragalysis</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="net_protocols.html" class="btn btn-neutral float-left" title="Channel Access and Other Protocols" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../how-to/add_ioc.html" class="btn btn-neutral float-right" title="Add an IOC instance to a beamline" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Diamond Light Source.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>